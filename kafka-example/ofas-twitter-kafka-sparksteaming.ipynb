{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Kafka parameters\n",
    "kafka_topic = \"test-ofas-demo-0\"\n",
    "\n",
    "# use local ip addresses in the format {ip}:{port} such as 10.0.0.1:9093, 10.0.0.2:9093, 10.0.0.3:9093\n",
    "kafka_bootstrap_servers = \"{local ip addresses with port}\"\n",
    "kafka_username = os.environ[\"KAFKA_USERNAME\"]\n",
    "kafka_password = os.environ[\"KAFKA_PASSWORD\"]\n",
    "kafka_security_protocol = \"SASL_PLAINTEXT\"\n",
    "kafka_sasl_mechanism = \"SCRAM-SHA-256\" \n",
    "kafka_sasl_jaas_config = f'org.apache.kafka.common.security.scram.ScramLoginModule required username=\"{kafka_username}\" password=\"{kafka_password}\";'\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following code reads events from kafka continuously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweets_df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", kafka_bootstrap_servers) \\\n",
    "    .option(\"subscribe\", kafka_topic) \\\n",
    "    .option(\"kafka.security.protocol\", kafka_security_protocol) \\\n",
    "    .option(\"kafka.sasl.mechanism\", kafka_sasl_mechanism) \\\n",
    "    .option(\"kafka.sasl.jaas.config\", kafka_sasl_jaas_config) \\\n",
    "    .option(\"kafka.socket.connection.setup.timeout.ms\", \"300000\") \\\n",
    "    .option(\"startingOffsets\", \"latest\") \\\n",
    "    .load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = tweets_df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\") \\\n",
    "    .withColumnRenamed(\"key\", \"keyword\") \\\n",
    "    .withColumnRenamed(\"value\", \"tweet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ignore the following code if you don't want to use text analytics using Azure Cognitive services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#azure_endpoint = os.environ.get('ACLS_LANGUAGE_ENDPOINT')\n",
    "#azure_api_key = os.environ.get('ACLS_LANGUAGE_KEY')\n",
    "#set azure end point for the text analytics service such as ofas-kafka-reference-app\n",
    "end_point = \"{azure text analytics endpoint}\"\n",
    "azure_endpoint = f\"https://{end_point}.cognitiveservices.azure.com/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(azure_api_key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "        endpoint=azure_endpoint, credential=ta_credential)\n",
    "    return text_analytics_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = authenticate_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize a DataFrame to store aggregated sentiment scores and counts\n",
    "sentiment_summary = pd.DataFrame(columns=[\"keyword\", \"total_sentiment\", \"count\"])\n",
    "\n",
    "def process_batch(batch_df, batch_id):\n",
    "    global sentiment_summary\n",
    "\n",
    "    batch_df = batch_df.toPandas()\n",
    "\n",
    "    for index, row in batch_df.iterrows():\n",
    "        keyword = row[\"keyword\"]\n",
    "        tweet = row[\"tweet\"]\n",
    "\n",
    "        # Analyze sentiment\n",
    "        sentiment_analysis = client.analyze_sentiment(documents=[tweet])[0]\n",
    "        sentiment_score = sentiment_analysis.confidence_scores.positive\n",
    "\n",
    "        # Update sentiment_summary DataFrame\n",
    "        if keyword in sentiment_summary[\"keyword\"].values:\n",
    "            sentiment_summary.loc[sentiment_summary[\"keyword\"] == keyword, \"total_sentiment\"] += sentiment_score\n",
    "            sentiment_summary.loc[sentiment_summary[\"keyword\"] == keyword, \"count\"] += 1\n",
    "        else:\n",
    "            sentiment_summary = sentiment_summary.append({\"keyword\": keyword, \"total_sentiment\": sentiment_score, \"count\": 1}, ignore_index=True)\n",
    "\n",
    "        # Print keyword, tweet, and sentiment score\n",
    "        print(f\"Keyword: {keyword}\\nTweet: {tweet}\\nSentiment Score: {sentiment_score}\\n---\")\n",
    "\n",
    "    # Calculate average sentiment score per keyword and print it\n",
    "    sentiment_summary[\"average_sentiment\"] = sentiment_summary[\"total_sentiment\"] / sentiment_summary[\"count\"]\n",
    "    print(\"Average Sentiment Scores per Keyword:\")\n",
    "    print(sentiment_summary[[\"keyword\", \"average_sentiment\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = tweets.writeStream \\\n",
    "    .foreachBatch(process_batch) \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .trigger(processingTime=\"5 seconds\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
